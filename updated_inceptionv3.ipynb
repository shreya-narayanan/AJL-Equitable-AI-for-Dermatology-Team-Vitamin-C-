{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DZE8Xeo5PtZh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eR6VBiLP6BL",
        "outputId": "ce8c7a55-8a90-4a61-c3e7-ca745bd1e05e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the updated training data\n",
        "data_path = \"/content/drive/My Drive/bttai-ajl-2025/updated_train.csv\"\n",
        "df = pd.read_csv(data_path)"
      ],
      "metadata": {
        "id": "DPclQVarQAJh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information about the dataset\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ULsFBxCQZgb",
        "outputId": "46648bef-dd0c-4c76-fa9c-5c1678cbb54f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            md5hash  fitzpatrick_scale  fitzpatrick_centaur  \\\n",
            "0  fd06d13de341cc75ad679916c5d7e6a6                  4                    4   \n",
            "1  a4bb4e5206c4e89a303f470576fc5253                  1                    1   \n",
            "2  c94ce27e389f96bda998e7c3fa5c4a2e                  5                    5   \n",
            "3  ebcf2b50dd943c700d4e2b586fcd4425                  3                    3   \n",
            "4  c77d6c895f05fea73a8f3704307036c0                  1                    1   \n",
            "\n",
            "                              label nine_partition_label  \\\n",
            "0                 prurigo-nodularis     benign-epidermal   \n",
            "1  basal-cell-carcinoma-morpheiform  malignant-epidermal   \n",
            "2                            keloid         inflammatory   \n",
            "3              basal-cell-carcinoma  malignant-epidermal   \n",
            "4                 prurigo-nodularis     benign-epidermal   \n",
            "\n",
            "  three_partition_label            qc  ddi_scale  \n",
            "0                benign           NaN         34  \n",
            "1             malignant           NaN         12  \n",
            "2        non-neoplastic  1 Diagnostic         56  \n",
            "3             malignant           NaN         34  \n",
            "4                benign           NaN         12  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/drive/My Drive/bttai-ajl-2025/train/train\"\n",
        "test_dir = \"/content/drive/My Drive/bttai-ajl-2025/test/test\""
      ],
      "metadata": {
        "id": "HMe_4rJHQ_y9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the full image paths to the dataframe, where labels are the subfolder names\n",
        "df[\"image_path\"] = df.apply(\n",
        "    lambda row: os.path.join(train_dir, row['label'], f\"{row['md5hash']}.jpg\"),\n",
        "    axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "dllYO7szRx8G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify the new column 'image_path' has been added\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NVkkN9YYOWr",
        "outputId": "ef42e639-6997-485d-87c4-517b185b0b2e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            md5hash  fitzpatrick_scale  fitzpatrick_centaur  \\\n",
            "0  fd06d13de341cc75ad679916c5d7e6a6                  4                    4   \n",
            "1  a4bb4e5206c4e89a303f470576fc5253                  1                    1   \n",
            "2  c94ce27e389f96bda998e7c3fa5c4a2e                  5                    5   \n",
            "3  ebcf2b50dd943c700d4e2b586fcd4425                  3                    3   \n",
            "4  c77d6c895f05fea73a8f3704307036c0                  1                    1   \n",
            "\n",
            "                              label nine_partition_label  \\\n",
            "0                 prurigo-nodularis     benign-epidermal   \n",
            "1  basal-cell-carcinoma-morpheiform  malignant-epidermal   \n",
            "2                            keloid         inflammatory   \n",
            "3              basal-cell-carcinoma  malignant-epidermal   \n",
            "4                 prurigo-nodularis     benign-epidermal   \n",
            "\n",
            "  three_partition_label            qc  ddi_scale  \\\n",
            "0                benign           NaN         34   \n",
            "1             malignant           NaN         12   \n",
            "2        non-neoplastic  1 Diagnostic         56   \n",
            "3             malignant           NaN         34   \n",
            "4                benign           NaN         12   \n",
            "\n",
            "                                          image_path  \n",
            "0  /content/drive/My Drive/bttai-ajl-2025/train/t...  \n",
            "1  /content/drive/My Drive/bttai-ajl-2025/train/t...  \n",
            "2  /content/drive/My Drive/bttai-ajl-2025/train/t...  \n",
            "3  /content/drive/My Drive/bttai-ajl-2025/train/t...  \n",
            "4  /content/drive/My Drive/bttai-ajl-2025/train/t...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where the image file is missing\n",
        "df = df[df[\"image_path\"].apply(lambda x: os.path.exists(x))]\n"
      ],
      "metadata": {
        "id": "CMblLKiSR2QI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define labels and prepare train-test split\n",
        "X = df[\"image_path\"]\n",
        "y = df[\"label\"]"
      ],
      "metadata": {
        "id": "7kCo__OWSBO5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "PKTUy3VOSFlF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data generators for training and validation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "M-jxO0i_SIlr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=pd.DataFrame({\"filename\": X_train, \"class\": y_train}),\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"class\",\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=pd.DataFrame({\"filename\": X_val, \"class\": y_val}),\n",
        "    x_col=\"filename\",\n",
        "    y_col=\"class\",\n",
        "    target_size=(299, 299),\n",
        "    batch_size=32,\n",
        "    class_mode=\"categorical\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vxjLlV0YhMm",
        "outputId": "e0ac4ec9-dc6f-41c4-d1e2-9b1252a12551"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2210 validated image filenames belonging to 21 classes.\n",
            "Found 553 validated image filenames belonging to 21 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Image size (ensure this matches the input size used during training)\n",
        "img_size = (299, 299)  # Adjust to the target_size used in your ImageDataGenerator\n",
        "\n",
        "# Load test images\n",
        "test_images = sorted(os.listdir(test_dir))  # Sort for consistency\n",
        "test_data = []\n",
        "\n",
        "# Load and preprocess each image in the test directory\n",
        "for img_name in test_images:\n",
        "    img_path = os.path.join(test_dir, img_name)\n",
        "    img = image.load_img(img_path, target_size=img_size)\n",
        "    img_array = image.img_to_array(img) / 255.0  # Normalize the image\n",
        "    test_data.append(img_array)\n",
        "\n",
        "test_data = np.array(test_data)"
      ],
      "metadata": {
        "id": "S8-G7Ph0YqGd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load Pretrained Model with the modified input shape\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))  # Change input shape\n",
        "\n",
        "# Freeze base layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add Custom Layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dense(len(train_generator.class_indices), activation='softmax')(x)  # Output classes\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (no change to the image size here)\n",
        "model.fit(train_generator, validation_data=val_generator, epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0bUeV_SaS3N",
        "outputId": "6e1b11bd-3c28-463a-80bd-50190056e7f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 12s/step - accuracy: 0.2319 - loss: 2.6938 - val_accuracy: 0.3562 - val_loss: 2.1283\n",
            "Epoch 2/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 11s/step - accuracy: 0.4545 - loss: 1.7494 - val_accuracy: 0.4702 - val_loss: 1.8950\n",
            "Epoch 3/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m724s\u001b[0m 10s/step - accuracy: 0.5716 - loss: 1.3762 - val_accuracy: 0.4430 - val_loss: 1.9012\n",
            "Epoch 4/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m777s\u001b[0m 11s/step - accuracy: 0.6324 - loss: 1.2071 - val_accuracy: 0.4340 - val_loss: 1.8826\n",
            "Epoch 5/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m817s\u001b[0m 12s/step - accuracy: 0.6742 - loss: 1.0372 - val_accuracy: 0.4539 - val_loss: 1.8815\n",
            "Epoch 6/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m803s\u001b[0m 12s/step - accuracy: 0.7114 - loss: 0.9358 - val_accuracy: 0.4810 - val_loss: 1.8754\n",
            "Epoch 7/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m763s\u001b[0m 11s/step - accuracy: 0.8000 - loss: 0.6897 - val_accuracy: 0.4665 - val_loss: 1.8609\n",
            "Epoch 8/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m852s\u001b[0m 12s/step - accuracy: 0.8494 - loss: 0.5777 - val_accuracy: 0.4430 - val_loss: 1.9489\n",
            "Epoch 9/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m759s\u001b[0m 11s/step - accuracy: 0.8904 - loss: 0.4805 - val_accuracy: 0.4684 - val_loss: 1.9240\n",
            "Epoch 10/10\n",
            "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m722s\u001b[0m 10s/step - accuracy: 0.9223 - loss: 0.3748 - val_accuracy: 0.4738 - val_loss: 2.0080\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d6b021c60d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_data)\n",
        "predicted_labels = [list(train_generator.class_indices.keys())[i] for i in predictions.argmax(axis=1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwBM7DtXbe_Y",
        "outputId": "66e1b7e8-8ad5-44c1-a7fa-b545deff375b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 8s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(f\"Validation Accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcaYmCmPvogG",
        "outputId": "cadd2163-9c10-4a41-f2b4-15b40cdffc71"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8s/step - accuracy: 0.4492 - loss: 2.0910\n",
            "Validation Accuracy: 0.4738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame({\n",
        "    \"md5hash\": [name[:-4] for name in test_images],  # Remove \".jpg\"\n",
        "    \"label\": predicted_labels\n",
        "})\n",
        "\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "6SZTDJFawW3G"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjwkIcFuw9en"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}